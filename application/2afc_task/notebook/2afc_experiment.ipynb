{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukas/opt/miniconda3/envs/bfPower/lib/python3.10/site-packages/bayesflow/trainers.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Get rid of annoying tf warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import bayesflow as beef\n",
    "import pandas as pd\n",
    "\n",
    "from experiments import RandomWalkDiffusionExperiment\n",
    "from models import RandomWalkDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If set to False, existing results will be loaded\n",
    "# Set to True if you want to re-run the experiments\n",
    "TRAIN_NETWORKS = True\n",
    "FIT_MODEL = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Performing 2 pilot runs with the random_walk_diffusion_model model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 80, 3)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 80)\n",
      "INFO:root:Shape of hyper_prior_draws batch after 2 pilot simulations: (batch_size = 2, 3)\n",
      "INFO:root:Shape of local_prior_draws batch after 2 pilot simulations: (batch_size = 2, 80, 3)\n",
      "INFO:root:No shared_prior_draws provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional prior non-batchable context provided.\n"
     ]
    }
   ],
   "source": [
    "model = RandomWalkDiffusion()\n",
    "neural_experiment = RandomWalkDiffusionExperiment(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_NETWORKS:\n",
    "    history = neural_experiment.run(\n",
    "        epochs=50, \n",
    "        iterations_per_epoch=1000, \n",
    "        batch_size=32\n",
    "    )\n",
    "else:\n",
    "    history = neural_experiment.trainer.loss_history.get_plottable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = beef.diagnostics.plot_losses(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/2afc_data.csv\")\n",
    "data[\"rt\"][data[\"correct\"] == 0] = -data[\"rt\"][data[\"correct\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OBS = 80\n",
    "N_SUB = len(np.unique(data['id']))\n",
    "N_SAMPLES = 2000\n",
    "\n",
    "LOCAL_PARAM_LABELS = ['Drift rate', 'Threshold', 'Non-decision time']\n",
    "LOCAL_PARAM_NAMES  = [r'v', r'a', r'\\tau']\n",
    "\n",
    "FONT_SIZE_1 = 16\n",
    "FONT_SIZE_2 = 14\n",
    "FONT_SIZE_3 = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "person_data = data[data['id'] == i+1]\n",
    "person_data = person_data['rt'].to_numpy()\n",
    "nan_idx = np.argwhere(np.isnan(person_data))\n",
    "tmp_data = person_data[np.isfinite(person_data)]\n",
    "tmp_data = {'summary_conditions': tmp_data[None, ..., None]}\n",
    "samples = neural_experiment.amortizer.sample(tmp_data, N_SAMPLES)['local_samples']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_MODEL:\n",
    "    post_samples = np.zeros((N_SUB, N_OBS, N_SAMPLES, 3))\n",
    "    padding = np.full((1, N_SAMPLES, 3), np.nan)\n",
    "    with tf.device('/cpu:0'):\n",
    "        for i in range(N_SUB):\n",
    "            person_data = data[data['id'] == i+1]\n",
    "            person_data = person_data['rt'].to_numpy()\n",
    "            nan_idx = np.argwhere(np.isnan(person_data))\n",
    "            tmp_data = person_data[np.isfinite(person_data)]\n",
    "            tmp_data = {'summary_conditions': tmp_data[None, ..., None]}\n",
    "            samples = neural_experiment.amortizer.sample(tmp_data, N_SAMPLES)['local_samples']\n",
    "            for idx in range(nan_idx.shape[0]):\n",
    "                start_idx = nan_idx[idx][0]\n",
    "                samples = np.concatenate(\n",
    "                    (samples[:start_idx, :, :], padding, samples[start_idx:, :, :]), axis=0\n",
    "                )\n",
    "            post_samples[i] = samples\n",
    "    np.save(\"../data/posterior_samples.npy\", post_samples)\n",
    "else:\n",
    "    post_samples = np.load(\"../data/posterior_samples.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples_not_z = post_samples * model.local_prior_stds + model.local_prior_means\n",
    "post_means = np.nanmean(post_samples_not_z, axis=2)\n",
    "post_means_mean = np.nanmean(post_means, axis=0)\n",
    "post_means_std = np.nanstd(post_means, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(3, 1, figsize=(15, 15))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.plot(\n",
    "        range(N_OBS), post_means_mean[:, i],\n",
    "        color='maroon', alpha=0.8\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        range(N_OBS),\n",
    "        post_means_mean[:, i] - post_means_std[:, i],\n",
    "        post_means_mean[:, i] + post_means_std[:, i],\n",
    "        color='maroon', alpha=0.3\n",
    "    )\n",
    "    ax.set_title(f'{LOCAL_PARAM_LABELS[i]} (${LOCAL_PARAM_NAMES[i]}$)', fontsize=FONT_SIZE_1)\n",
    "\n",
    "sns.despine()\n",
    "f.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
