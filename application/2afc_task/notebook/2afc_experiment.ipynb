{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukas/opt/miniconda3/envs/beef/lib/python3.11/site-packages/bayesflow/trainers.py:27: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Get rid of annoying tf warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import bayesflow as beef\n",
    "import pandas as pd\n",
    "\n",
    "from experiments import RandomWalkMixtureDiffusionExperiment\n",
    "from models import RandomWalkMixtureDiffusion\n",
    "from likelihoods import sample_random_walk_mixture_diffusion_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If set to False, existing results will be loaded\n",
    "# Set to True if you want to re-run the experiments\n",
    "TRAIN_NETWORKS = True\n",
    "FIT_MODEL = True\n",
    "POSTERIOR_RESIMULATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9390179213543888\n",
      "2.028260576415458\n",
      "0.7990345549609846\n",
      "0.032650979683351136\n",
      "1.4386990939464208\n",
      "1.5538571053824013\n",
      "0.5884961320102866\n",
      "0.0312614809009866\n"
     ]
    }
   ],
   "source": [
    "# simulate parameter trajectories to add p local prior in models.py\n",
    "from priors import sample_mixture_ddm_params\n",
    "import bayesflow as bf\n",
    "import numpy as np\n",
    "from statistics import mean, pstdev\n",
    "\n",
    "# Set the number of iterations for sampling\n",
    "num_iterations = 2000\n",
    "\n",
    "# Create an empty array to store parameter trajectories\n",
    "parameter_trajectories = np.zeros((num_iterations, 4))\n",
    "\n",
    "# Sampling loop\n",
    "for i in range(num_iterations):\n",
    "        # Sample parameters\n",
    "        sampled_params = sample_mixture_ddm_params()\n",
    "        \n",
    "        # Store the sampled parameters in the trajectory array\n",
    "        parameter_trajectories[i] = sampled_params\n",
    "\n",
    "print(mean(parameter_trajectories[:,0]))\n",
    "print(mean(parameter_trajectories[:,1]))\n",
    "print(mean(parameter_trajectories[:,2]))\n",
    "print(mean(parameter_trajectories[:,3]))\n",
    "print(pstdev(parameter_trajectories[:,0]))\n",
    "print(pstdev(parameter_trajectories[:,1]))\n",
    "print(pstdev(parameter_trajectories[:,2]))\n",
    "print(pstdev(parameter_trajectories[:,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Performing 2 pilot runs with the random_walk_mixture_diffusion_model model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 80, 4)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 80)\n",
      "INFO:root:Shape of hyper_prior_draws batch after 2 pilot simulations: (batch_size = 2, 4)\n",
      "INFO:root:Shape of local_prior_draws batch after 2 pilot simulations: (batch_size = 2, 80, 4)\n",
      "INFO:root:No shared_prior_draws provided.\n",
      "INFO:root:No optional simulation batchable context provided.\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional prior non-batchable context provided.\n"
     ]
    }
   ],
   "source": [
    "model = RandomWalkMixtureDiffusion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initialized empty loss history.\n",
      "INFO:root:Initialized networks from scratch.\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n"
     ]
    }
   ],
   "source": [
    "neural_experiment = RandomWalkMixtureDiffusionExperiment(model, checkpoint_path=\"../checkpoints/2afc_task_mixture_ddm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_NETWORKS:\n",
    "    history = neural_experiment.run(\n",
    "        epochs=50, \n",
    "        iterations_per_epoch=1000, \n",
    "        batch_size=32\n",
    "    )\n",
    "else:\n",
    "    history = neural_experiment.trainer.loss_history.get_plottable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = beef.diagnostics.plot_losses(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/2afc_data.csv\")\n",
    "data[\"rt\"][data[\"correct\"] == 0] = -data[\"rt\"][data[\"correct\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OBS = 80\n",
    "N_SUB = len(np.unique(data['id']))\n",
    "N_SAMPLES = 2000\n",
    "N_RESIM = 200\n",
    "\n",
    "LOCAL_PARAM_LABELS = ['Drift rate', 'Threshold', 'Non-decision time']\n",
    "LOCAL_PARAM_NAMES  = [r'v', r'a', r'\\tau']\n",
    "\n",
    "FONT_SIZE_1 = 18\n",
    "FONT_SIZE_2 = 16\n",
    "FONT_SIZE_3 = 12\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Palatino\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_MODEL:\n",
    "    post_samples = np.zeros((N_SUB, N_OBS, N_SAMPLES, 3))\n",
    "    padding = np.full((1, N_SAMPLES, 3), np.nan)\n",
    "    with tf.device('/cpu:0'):\n",
    "        for i in range(N_SUB):\n",
    "            person_data = data[data['id'] == i+1]\n",
    "            person_data = person_data['rt'].to_numpy()\n",
    "            nan_idx = np.argwhere(np.isnan(person_data))\n",
    "            tmp_data = person_data[np.isfinite(person_data)]\n",
    "            tmp_data = {'summary_conditions': tmp_data[None, ..., None]}\n",
    "            samples = neural_experiment.amortizer.sample(tmp_data, N_SAMPLES)['local_samples']\n",
    "            for idx in range(nan_idx.shape[0]):\n",
    "                start_idx = nan_idx[idx][0]\n",
    "                samples = np.concatenate(\n",
    "                    (samples[:start_idx, :, :], padding, samples[start_idx:, :, :]), axis=0\n",
    "                )\n",
    "            post_samples[i] = samples\n",
    "    np.save(\"../data/posterior_samples.npy\", post_samples)\n",
    "else:\n",
    "    post_samples = np.load(\"../data/posterior_samples.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples_not_z = post_samples * model.local_prior_stds + model.local_prior_means\n",
    "post_means = np.nanmean(post_samples_not_z, axis=2)\n",
    "post_means_mean = np.nanmean(post_means, axis=0)\n",
    "post_means_std = np.nanstd(post_means, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(15, 3))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.plot(\n",
    "        range(N_OBS), post_means_mean[:, i],\n",
    "        color='maroon', alpha=0.8\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        range(N_OBS),\n",
    "        post_means_mean[:, i] - post_means_std[:, i],\n",
    "        post_means_mean[:, i] + post_means_std[:, i],\n",
    "        color='maroon', alpha=0.3\n",
    "    )\n",
    "    ax.set_title(f'{LOCAL_PARAM_LABELS[i]} (${LOCAL_PARAM_NAMES[i]}$)', fontsize=FONT_SIZE_1)\n",
    "    ax.grid(alpha=0.4)\n",
    "\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "    ax.set_xlabel(\"Time\", fontsize=FONT_SIZE_2)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    ax.set_xticks([1, 20, 40, 60, 80])\n",
    "\n",
    "sns.despine()\n",
    "f.tight_layout()\n",
    "\n",
    "plt.savefig('../plots/parameter_dynamic_2afc.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior resimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if POSTERIOR_RESIMULATION:\n",
    "    pred_data = np.zeros((N_RESIM, N_SUB, N_OBS, 1))\n",
    "    for s in range(N_SUB):\n",
    "        post_idx = np.random.choice(np.arange(N_SAMPLES), N_RESIM)\n",
    "        for i in range(N_RESIM):\n",
    "            idx = post_idx[i]\n",
    "            pred_data[i, s] = sample_random_walk_mixture_diffusion_process(post_samples_not_z[s, :, idx])[:, None]\n",
    "    np.save(\"../data/posterior_resimulation_hehe_hetero.npy\", pred_data)\n",
    "else:\n",
    "    pred_data = np.load(\"../data/posterior_resimulation_hehe_hetero.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
