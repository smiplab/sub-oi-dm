{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukas/opt/miniconda3/envs/bfPower/lib/python3.10/site-packages/bayesflow/trainers.py:26: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "# Get rid of annoying tf warning\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import bayesflow as beef\n",
    "import pandas as pd\n",
    "\n",
    "from experiments import RandomWalkDiffusionExperiment\n",
    "from models import RandomWalkDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If set to False, existing results will be loaded\n",
    "# Set to True if you want to re-run the experiments\n",
    "TRAIN_NETWORKS = False\n",
    "FIT_MODEL = False\n",
    "\n",
    "N_SAMPLES = 2000\n",
    "\n",
    "LOCAL_PARAM_LABELS = ['Drift rate', 'Drift rate', 'Threshold', 'Non-decision time', 'Bias']\n",
    "LOCAL_PARAM_NAMES  = [r'v_1', r'v_2', r'a', r'\\tau', r'\\beta']\n",
    "\n",
    "FONT_SIZE_1 = 18\n",
    "FONT_SIZE_2 = 16\n",
    "FONT_SIZE_3 = 12\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams['font.sans-serif'] = \"Palatino\"\n",
    "matplotlib.rcParams['font.family'] = \"sans-serif\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Performing 2 pilot runs with the random_walk_diffusion_model model...\n",
      "INFO:root:Shape of parameter batch after 2 pilot simulations: (batch_size = 2, 112, 5)\n",
      "INFO:root:Shape of simulation batch after 2 pilot simulations: (batch_size = 2, 112)\n",
      "INFO:root:Shape of hyper_prior_draws batch after 2 pilot simulations: (batch_size = 2, 5)\n",
      "INFO:root:Shape of local_prior_draws batch after 2 pilot simulations: (batch_size = 2, 112, 5)\n",
      "INFO:root:No shared_prior_draws provided.\n",
      "INFO:root:Could not determine shape of simulation batchable context. Type appears to be non-array: <class 'list'>,                                    so make sure your input configurator takes care of that!\n",
      "INFO:root:No optional simulation non-batchable context provided.\n",
      "INFO:root:No optional prior batchable context provided.\n",
      "INFO:root:No optional prior non-batchable context provided.\n",
      "INFO:root:Initialized empty loss history.\n",
      "INFO:root:Initialized networks from scratch.\n",
      "INFO:root:Performing a consistency check with provided components...\n",
      "INFO:root:Done.\n"
     ]
    }
   ],
   "source": [
    "model = RandomWalkDiffusion()\n",
    "neural_experiment = RandomWalkDiffusionExperiment(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99959f8adb54485a9ea99885ed960b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training epoch 1:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if TRAIN_NETWORKS:\n",
    "    history = neural_experiment.run(\n",
    "        epochs=50, \n",
    "        iterations_per_epoch=1000, \n",
    "        batch_size=32\n",
    "    )\n",
    "else:\n",
    "    history = neural_experiment.trainer.loss_history.get_plottable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = beef.diagnostics.plot_losses(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/yes_no_pictures_data.csv\")\n",
    "data[\"rt\"][data[\"new_resp\"] == 1] = -data[\"rt\"][data[\"new_resp\"] == 1]\n",
    "N_OBS = 107\n",
    "N_SUB = len(np.unique(data['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FIT_MODEL:\n",
    "    post_samples = np.full((N_SUB, N_OBS, N_SAMPLES, 5), np.nan)\n",
    "    with tf.device('/cpu:0'):\n",
    "        for i in range(N_SUB):\n",
    "            person_data = data[data['id'] == i+1]\n",
    "            rt = person_data['rt'].to_numpy()\n",
    "            context = person_data['new_item'].to_numpy()\n",
    "            mask = np.isfinite(rt)\n",
    "            person_data = np.c_[rt, context]\n",
    "            person_data = person_data[mask, :]\n",
    "            tmp_data = {'summary_conditions': person_data[None, :, :]}\n",
    "            samples = neural_experiment.amortizer.sample(tmp_data, N_SAMPLES)['local_samples']\n",
    "            post_samples[i, mask, :, :] = samples\n",
    "        np.save(\"../data/posterior_samples_pictures.npy\", post_samples)\n",
    "else:\n",
    "    post_samples = np.load(\"../data/posterior_samples_pictures.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_samples_not_z = post_samples * model.local_prior_stds + model.local_prior_means\n",
    "post_means = np.nanmean(post_samples_not_z, axis=2)\n",
    "post_std = np.nanstd(post_samples_not_z, axis=2)\n",
    "post_means_mean = np.nanmean(post_means, axis=0)\n",
    "post_means_std = np.nanstd(post_means, axis=0)\n",
    "np.save(\"../data/posterior_means.npy\", post_means)\n",
    "post_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.plot(\n",
    "        range(N_OBS), post_means_mean[:, i],\n",
    "        color='maroon'\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        range(N_OBS),\n",
    "        post_means_mean[:, i] - post_means_std[:, i],\n",
    "        post_means_mean[:, i] + post_means_std[:, i],\n",
    "        color='maroon', alpha=0.6\n",
    "    )\n",
    "    ax.set_title(f'{LOCAL_PARAM_LABELS[i]} (${LOCAL_PARAM_NAMES[i]}$)', fontsize=FONT_SIZE_1)\n",
    "\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    if i == 0 or i == 2:\n",
    "        ax.set_ylim([0.0, 3.0])\n",
    "    if i ==1 :\n",
    "        ax.set_ylim([-3.0, 0.0])\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "    ax.set_xlabel(\"Time\", fontsize=FONT_SIZE_2)\n",
    "\n",
    "sns.despine()\n",
    "f.tight_layout()\n",
    "plt.savefig('../plots/parameter_dynamic_1.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for i, ax in enumerate(axarr.flat):\n",
    "    if i == 2:\n",
    "        break\n",
    "    ax.grid(alpha=0.5)\n",
    "    ax.plot(\n",
    "        range(N_OBS), post_means_mean[:, i+3],\n",
    "        color='maroon'\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        range(N_OBS),\n",
    "        post_means_mean[:, i+3] - post_means_std[:, i+3],\n",
    "        post_means_mean[:, i+3] + post_means_std[:, i+3],\n",
    "        color='maroon', alpha=0.6\n",
    "    )\n",
    "    ax.set_title(f'{LOCAL_PARAM_LABELS[i+3]} (${LOCAL_PARAM_NAMES[i+3]}$)', fontsize=FONT_SIZE_1)\n",
    "\n",
    "    \n",
    "    ax.tick_params(axis='both', which='major', labelsize=FONT_SIZE_3)\n",
    "    if i+3 == 0 or i+3 == 2:\n",
    "        ax.set_ylim([0.0, 3.0])\n",
    "    if i+3 ==1 :\n",
    "        ax.set_ylim([-3.0, 0.0])\n",
    "    if i+3 == 0:\n",
    "        ax.set_ylabel(\"Parameter value\", fontsize=FONT_SIZE_2)\n",
    "    ax.set_xlabel(\"Time\", fontsize=FONT_SIZE_2)\n",
    "\n",
    "sns.despine()\n",
    "# f.tight_layout()\n",
    "\n",
    "plt.savefig('../plots/parameter_dynamic_2.png', dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior resimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_RESIM = 100 # randomly sample from posterior\n",
    "\n",
    "\n",
    "pred_data = np.zeros((N_RESIM, N_SUB, N_OBS, 1))\n",
    "# for\n",
    "\n",
    "post_samples.shape\n",
    "\n",
    "post_samples[0, :, 345, :]\n",
    "\n",
    "sample_random_walk_diffusion_process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bfPower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
